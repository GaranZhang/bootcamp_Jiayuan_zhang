{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f600aeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10341\\AppData\\Local\\Temp\\ipykernel_27808\\514959559.py:37: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_api = yf.download(SYMBOL, period=\"6mo\", interval=\"1d\").reset_index()[[\"Date\",\"Close\"]]\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation (yfinance): {'missing': [], 'shape': (125, 2), 'na_total': 0}\n",
      "Saved data\\raw\\api_source-yfinance_symbol-STX_20250820-232100.csv\n",
      "Validation (scrape): {'missing': [], 'shape': (25, 12), 'na_total': 50}\n",
      "Saved data\\raw\\scrape_site-yahoo_table-most_active_20250820-232101.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10341\\AppData\\Local\\Temp\\ipykernel_27808\\514959559.py:73: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df_scrape[col] = pd.to_numeric(df_scrape[col], errors=\"ignore\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        date  adj_close\n",
       " 0 2025-02-21  99.502449\n",
       " 1 2025-02-24  98.742737\n",
       " 2 2025-02-25  98.387543\n",
       " 3 2025-02-26  98.930191\n",
       " 4 2025-02-27  99.324852,\n",
       "   Symbol                        Name                       Price  Change  \\\n",
       " 0   OPEN  Opendoor Technologies Inc. NaN  3.2200-0.4000(-11.05%)   -0.40   \n",
       " 1   PLTR  Palantir Technologies Inc. NaN     156.01-1.74(-1.10%)   -1.74   \n",
       " 2   NVDA          NVIDIA Corporation NaN     175.40-0.24(-0.14%)   -0.24   \n",
       " 3   INTC           Intel Corporation NaN      23.54-1.77(-6.99%)   -1.77   \n",
       " 4   SOFI     SoFi Technologies, Inc. NaN      22.52-0.23(-1.01%)   -0.23   \n",
       " \n",
       "   Change %    Volume Avg Vol (3M) Market Cap P/E Ratio(TTM) 52 WkChange %  \\\n",
       " 0  -11.05%  239.019M     211.012M      2.37B             --       +59.41%   \n",
       " 1   -1.10%  215.789M      76.305M   370.109B         520.03      +388.75%   \n",
       " 2   -0.14%    213.1M     180.756M     4.278T          56.76       +41.75%   \n",
       " 3   -6.99%  158.767M     100.132M   103.035B             --       +17.11%   \n",
       " 4   -1.01%   87.254M      71.011M    26.967B          45.04      +213.21%   \n",
       " \n",
       "    52 Wk Range  \n",
       " 0          NaN  \n",
       " 1          NaN  \n",
       " 2          NaN  \n",
       " 3          NaN  \n",
       " 4          NaN  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stage 04: Data Acquisition & Ingestion\n",
    "\n",
    "\n",
    "import os, pathlib, datetime as dt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "\n",
    "# --- Setup paths ---\n",
    "RAW = pathlib.Path(\"data/raw\")\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ts():\n",
    "    \"\"\"Generate timestamp string for file naming\"\"\"\n",
    "    return dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def save_csv(df: pd.DataFrame, prefix: str, **meta):\n",
    "    \"\"\"Save dataframe to /data/raw with metadata in filename\"\"\"\n",
    "    mid = \"_\".join([f\"{k}-{v}\" for k, v in meta.items()])\n",
    "    path = RAW / f\"{prefix}_{mid}_{ts()}.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print(\"Saved\", path)\n",
    "    return path\n",
    "\n",
    "def validate(df: pd.DataFrame, required):\n",
    "    \"\"\"Check for required columns and missing values\"\"\"\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    return {\n",
    "        \"missing\": missing,\n",
    "        \"shape\": df.shape,\n",
    "        \"na_total\": int(df.isna().sum().sum())\n",
    "    }\n",
    "\n",
    "\n",
    "SYMBOL = \"STX\"  # Seagate Technology\n",
    "df_api = yf.download(SYMBOL, period=\"6mo\", interval=\"1d\").reset_index()[[\"Date\",\"Close\"]]\n",
    "df_api.columns = [\"date\",\"adj_close\"]\n",
    "\n",
    "v_api = validate(df_api, [\"date\",\"adj_close\"])\n",
    "print(\"Validation (yfinance):\", v_api)\n",
    "\n",
    "_ = save_csv(df_api.sort_values(\"date\"), prefix=\"api\", source=\"yfinance\", symbol=SYMBOL)\n",
    "\n",
    "\n",
    "\n",
    "SCRAPE_URL = \"https://finance.yahoo.com/most-active\"\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (compatible; AFE-Homework/1.0)\"}\n",
    "\n",
    "try:\n",
    "    resp = requests.get(SCRAPE_URL, headers=headers, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    rows = [\n",
    "        [c.get_text(strip=True) for c in tr.find_all([\"th\",\"td\"])]\n",
    "        for tr in soup.find_all(\"tr\")\n",
    "    ]\n",
    "    header, *data = [r for r in rows if r]\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "except Exception as e:\n",
    "    print(\"Scrape failed, fallback to demo:\", e)\n",
    "    html = \"<table><tr><th>Ticker</th><th>Price</th></tr><tr><td>AAA</td><td>101.2</td></tr></table>\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    rows = [\n",
    "        [c.get_text(strip=True) for c in tr.find_all([\"th\",\"td\"])]\n",
    "        for tr in soup.find_all(\"tr\")\n",
    "    ]\n",
    "    header, *data = [r for r in rows if r]\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "\n",
    "for col in df_scrape.columns:\n",
    "    df_scrape[col] = pd.to_numeric(df_scrape[col], errors=\"ignore\")\n",
    "\n",
    "v_scrape = validate(df_scrape, list(df_scrape.columns))\n",
    "print(\"Validation (scrape):\", v_scrape)\n",
    "\n",
    "_ = save_csv(df_scrape, prefix=\"scrape\", site=\"yahoo\", table=\"most_active\")\n",
    "\n",
    "df_api.head(), df_scrape.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fe-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
